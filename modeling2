
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from collections import deque
import tensorflow as tf
from datetime import datetime
import psycopg2
import redis

# 딥러닝 모델 로드
model = tf.keras.models.load_model("C:\\Users\\Jsystem\\.cache\\huggingface\\hub\\models--keras-io--timeseries-anomaly-detection\\snapshots\\57126012e02dcab3a653501f12cb599c4a51db7a")

# 데이터 정규화 스케일러
scaler = MinMaxScaler()

# 시계열 데이터 큐 초기화 (시퀀스 길이만큼 유지)
sequence_length = 288
data_queue = deque(maxlen=sequence_length)


# 데이터베이스 연결 설정
conn = psycopg2.connect(
    dbname="postgres",
    user="postgres",
    password="1234",
    host="localhost",
    port="5432"
)
cursor = conn.cursor()

# Redis 연결 설정
client = redis.from_url('redis://localhost')
pipeline = client.pipeline()
stream_name = 'sensorDataStream'



# Redis 및 데이터베이스에 저장 함수
def save_to_db_and_redis(sensor_id, time, value, prediction, is_outlier):
    data = (sensor_id, time, value, prediction, is_outlier)
    
    # 데이터베이스에 저장
    try:
        cursor.execute("""
            INSERT INTO vibration (sensor_id, time, value, prediction, outlier_status)
            VALUES (%s, %s, %s, %s, %s)
        """, data)
        conn.commit()
    except Exception as e:
        print(f"Database insertion error: {e}")
        conn.rollback()

    # Redis Stream 저장
    stream_data = {
        "sensorId": sensor_id,
        "time": str(time),
        "value": value,
        "prediction": prediction,
        "outlierStatus": str(is_outlier)
    }
    pipeline.xadd(stream_name, stream_data, maxlen=2000)
    pipeline.execute()

# 이상치 탐지 함수
def detect_outlier_with_model(new_value):
    # 데이터 정규화 및 큐에 추가
    normalized_value = scaler.transform([[new_value]])[0][0]
    data_queue.append(normalized_value)
    
    # 시퀀스가 충분히 쌓인 경우
    if len(data_queue) == sequence_length:
        input_sequence = np.array(data_queue).reshape(1, sequence_length, 1)
        prediction = model.predict(input_sequence)[0][0]
        
        # 이상치 판단 (임계값 설정 가능)
        threshold = 0.1
        is_outlier = abs(new_value - prediction) > threshold
        return prediction, is_outlier
    return None, None




# 실시간 데이터 처리
def process_real_time_data(sensor_id, raw_value):
    current_time = datetime.now()
    
    # 모델 기반 이상치 탐지
    prediction, is_outlier = detect_outlier_with_model(raw_value)
    
    # 결과 저장
    if prediction is not None:
        save_to_db_and_redis(sensor_id, current_time, raw_value, prediction, is_outlier)


if __name__ == "__main__":
# def main():
    print("----- 센서 데이터 수집 시작 -----")
    
    while True:
        # 함수 실행 시작 시간
        start = time.time();
        
        # PLC 데이터 모두 읽기
        das_db = plc.db_read(7, 0, 168)
        sensor_db2 = plc.db_read(4, 0, 2)
    
        # PLC 데이터 블록에서 값 읽기
        # 인버터 데이터 
        current_cv = snap7.util.get_int(das_db, 0) / 10
        frequency_cv = snap7.util.get_int(das_db, 2) / 100
        frequency_sv = snap7.util.get_int(sensor_db2, 0) / 100
        voltage = snap7.util.get_int(das_db, 4)
        power = snap7.util.get_int(das_db, 6) 

        # 온도, 습도 데이터 
        temp = snap7.util.get_real(das_db, 8)
        rh = snap7.util.get_real(das_db, 12)

        # 진동센서 1
        # 가속도 데이터 
        axis_acc = {
            "x_axis": snap7.util.get_real(das_db, 16),
            "y_axis": snap7.util.get_real(das_db, 20),
            "z_axis": snap7.util.get_real(das_db, 24)
        }

        # 각속도 데이터 
        ang_vel = {
            "x_axis": snap7.util.get_real(das_db, 28),
            "y_axis": snap7.util.get_real(das_db, 32),
            "z_axis": snap7.util.get_real(das_db, 36)
        }

        # 진동 속도 데이터 읽기
        vib_sp = {
            "x_axis": snap7.util.get_real(das_db, 40),
            "y_axis": snap7.util.get_real(das_db, 44),
            "z_axis": snap7.util.get_real(das_db, 48)
        }

        # 진동센서 2
        # 가속도 데이터 
        axis_acc2 = {
            "x_axis": snap7.util.get_real(das_db, 96),
            "y_axis": snap7.util.get_real(das_db, 100),
            "z_axis": snap7.util.get_real(das_db, 104)
        }

        # 각속도 데이터 
        ang_vel2 = {
            "x_axis": snap7.util.get_real(das_db, 108),
            "y_axis": snap7.util.get_real(das_db, 112),
            "z_axis": snap7.util.get_real(das_db, 116)
        }

        # 진동 속도 데이터 읽기
        vib_sp2 = {
            "x_axis": snap7.util.get_real(das_db, 120),
            "y_axis": snap7.util.get_real(das_db, 124),
            "z_axis": snap7.util.get_real(das_db, 128)
        }

        # 인버터, 온도, 습도 데이터 상한선/하한선, 이상치 상태
        upper_limit_temp, lower_limit_temp, outlier_status_temp = process_sensor_data(temp, data_queues['temperature'][1]['temp'])
        upper_limit_rh, lower_limit_rh, outlier_status_rh = process_sensor_data(rh, data_queues['rh'][2]['rh'])
        upper_limit_current_cv, lower_limit_current_cv, outlier_status_current_cv = process_sensor_data(current_cv, data_queues['inverter'][3]['current_cv'])
        upper_limit_frequency_cv, lower_limit_frequency_cv, outlier_status_frequency_cv = process_sensor_data(frequency_cv, data_queues['inverter'][3]['frequency_cv'])
        upper_limit_voltage, lower_limit_voltage, outlier_status_voltage = process_sensor_data(voltage, data_queues['inverter'][3]['voltage'])

        # 진동 데이터 FFT 필터 적용 값, 상한선/하한선, 이상치 상태
        filtered_x_acc, upper_limit_x, lower_limit_x, outlier_status_x = process_vibration_data(axis_acc['x_axis'], data_queues['vibration'][4]['x_acc'], data_queues['vibration'][4]['filtered_x_acc'])
        filtered_y_acc, upper_limit_y, lower_limit_y, outlier_status_y = process_vibration_data(axis_acc['y_axis'], data_queues['vibration'][4]['y_acc'], data_queues['vibration'][4]['filtered_y_acc'])
        filtered_z_acc, upper_limit_z, lower_limit_z, outlier_status_z = process_vibration_data(axis_acc['z_axis'], data_queues['vibration'][4]['z_acc'], data_queues['vibration'][4]['filtered_z_acc'])
        
        filtered_x_ang_vel, upper_limit_ang_x, lower_limit_ang_x, outlier_status_ang_x = process_vibration_data(ang_vel["x_axis"], data_queues['vibration'][4]['x_ang_vel'], data_queues['vibration'][4]['filtered_x_ang_vel'])
        filtered_y_ang_vel, upper_limit_ang_y, lower_limit_ang_y, outlier_status_ang_y = process_vibration_data(ang_vel["y_axis"], data_queues['vibration'][4]['y_ang_vel'], data_queues['vibration'][4]['filtered_y_ang_vel'])
        filtered_z_ang_vel, upper_limit_ang_z, lower_limit_ang_z, outlier_status_ang_z = process_vibration_data(ang_vel["z_axis"], data_queues['vibration'][4]['z_ang_vel'], data_queues['vibration'][4]['filtered_z_ang_vel'])

        filtered_x_vib_sp, upper_limit_vib_x, lower_limit_vib_x, outlier_status_vib_x = process_vibration_data(vib_sp["x_axis"], data_queues['vibration'][4]['x_vib_sp'], data_queues['vibration'][4]['filtered_x_vib_sp'])
        filtered_y_vib_sp, upper_limit_vib_y, lower_limit_vib_y, outlier_status_vib_y = process_vibration_data(vib_sp["y_axis"], data_queues['vibration'][4]['y_vib_sp'], data_queues['vibration'][4]['filtered_y_vib_sp'])
        filtered_z_vib_sp, upper_limit_vib_z, lower_limit_vib_z, outlier_status_vib_z = process_vibration_data(vib_sp["z_axis"], data_queues['vibration'][4]['z_vib_sp'], data_queues['vibration'][4]['filtered_z_vib_sp'])

        # 진동 데이터 2 FFT 필터 적용 값, 상한선/하한선, 이상치 상태
        filtered_x_acc2, upper_limit_x2, lower_limit_x2, outlier_status_x2 = process_vibration_data(axis_acc2['x_axis'], data_queues['vibration'][5]['x_acc'], data_queues['vibration'][5]['filtered_x_acc'])
        filtered_y_acc2, upper_limit_y2, lower_limit_y2, outlier_status_y2 = process_vibration_data(axis_acc2['y_axis'], data_queues['vibration'][5]['y_acc'], data_queues['vibration'][5]['filtered_y_acc'])
        filtered_z_acc2, upper_limit_z2, lower_limit_z2, outlier_status_z2 = process_vibration_data(axis_acc2['z_axis'], data_queues['vibration'][5]['z_acc'], data_queues['vibration'][5]['filtered_z_acc'])
        
        filtered_x_ang_vel2, upper_limit_ang_x2, lower_limit_ang_x2, outlier_status_ang_x2 = process_vibration_data(ang_vel2["x_axis"], data_queues['vibration'][5]['x_ang_vel'], data_queues['vibration'][5]['filtered_x_ang_vel'])
        filtered_y_ang_vel2, upper_limit_ang_y2, lower_limit_ang_y2, outlier_status_ang_y2 = process_vibration_data(ang_vel2["y_axis"], data_queues['vibration'][5]['y_ang_vel'], data_queues['vibration'][5]['filtered_y_ang_vel'])
        filtered_z_ang_vel2, upper_limit_ang_z2, lower_limit_ang_z2, outlier_status_ang_z2 = process_vibration_data(ang_vel2["z_axis"], data_queues['vibration'][5]['z_ang_vel'], data_queues['vibration'][5]['filtered_z_ang_vel'])

        filtered_x_vib_sp2, upper_limit_vib_x2, lower_limit_vib_x2, outlier_status_vib_x2 = process_vibration_data(vib_sp2["x_axis"], data_queues['vibration'][5]['x_vib_sp'], data_queues['vibration'][5]['filtered_x_vib_sp'])
        filtered_y_vib_sp2, upper_limit_vib_y2, lower_limit_vib_y2, outlier_status_vib_y2 = process_vibration_data(vib_sp2["y_axis"], data_queues['vibration'][5]['y_vib_sp'], data_queues['vibration'][5]['filtered_y_vib_sp'])
        filtered_z_vib_sp2, upper_limit_vib_z2, lower_limit_vib_z2, outlier_status_vib_z2 = process_vibration_data(vib_sp2["z_axis"], data_queues['vibration'][5]['z_vib_sp'], data_queues['vibration'][5]['filtered_z_vib_sp'])

        # 현재 시간
        current_time = datetime.now()
    
        # 각 센서 데이터 삽입 준비
        sensor_data_list = [
            (1, 1, current_time, temp, upper_limit_temp, lower_limit_temp, outlier_status_temp, None),
            (1, 2, current_time, rh, upper_limit_rh, lower_limit_rh, outlier_status_rh, None),
            
            (1, 3, current_time, current_cv, upper_limit_current_cv, lower_limit_current_cv, outlier_status_current_cv, None),
            (1, 4, current_time, frequency_cv, upper_limit_frequency_cv, lower_limit_frequency_cv, outlier_status_frequency_cv, None),
            # (5, current_time, frequency_sv, None, None, None, None),  # frequency_sv의 상한선, 하한선, 이상탐지값은 결측치로 설정
            (1, 6, current_time, voltage, upper_limit_voltage, lower_limit_voltage, outlier_status_voltage, None),
            
            (1, 7, current_time, axis_acc["x_axis"], upper_limit_x, lower_limit_x, outlier_status_x, filtered_x_acc),
            (1, 8, current_time, axis_acc["y_axis"], upper_limit_y, lower_limit_y, outlier_status_y, filtered_y_acc),
            (1, 9, current_time, axis_acc["z_axis"], upper_limit_z, lower_limit_z, outlier_status_z, filtered_z_acc),
            
            (1, 10, current_time, ang_vel["x_axis"], upper_limit_ang_x, lower_limit_ang_x, outlier_status_ang_x, filtered_x_ang_vel),
            (1, 11, current_time, ang_vel["y_axis"], upper_limit_ang_y, lower_limit_ang_y, outlier_status_ang_y, filtered_y_ang_vel),
            (1, 12, current_time, ang_vel["z_axis"], upper_limit_ang_z, lower_limit_ang_z, outlier_status_ang_z, filtered_z_ang_vel),
            
            (1, 13, current_time, vib_sp["x_axis"], upper_limit_vib_x, lower_limit_vib_x, outlier_status_vib_x, filtered_x_vib_sp),
            (1, 14, current_time, vib_sp["y_axis"], upper_limit_vib_y, lower_limit_vib_y, outlier_status_vib_y, filtered_y_vib_sp),
            (1, 15, current_time, vib_sp["z_axis"], upper_limit_vib_z, lower_limit_vib_z, outlier_status_vib_z, filtered_z_vib_sp),

            (1, 16, current_time, axis_acc2["x_axis"], upper_limit_x2, lower_limit_x2, outlier_status_x2, filtered_x_acc2),
            (1, 17, current_time, axis_acc2["y_axis"], upper_limit_y2, lower_limit_y2, outlier_status_y2, filtered_y_acc2),
            (1, 18, current_time, axis_acc2["z_axis"], upper_limit_z2, lower_limit_z2, outlier_status_z2, filtered_z_acc2),
            
            (1, 19, current_time, ang_vel2["x_axis"], upper_limit_ang_x2, lower_limit_ang_x2, outlier_status_ang_x2, filtered_x_ang_vel2),
            (1, 20, current_time, ang_vel2["y_axis"], upper_limit_ang_y2, lower_limit_ang_y2, outlier_status_ang_y2, filtered_y_ang_vel2),
            (1, 21, current_time, ang_vel2["z_axis"], upper_limit_ang_z2, lower_limit_ang_z2, outlier_status_ang_z2, filtered_z_ang_vel2),
            
            (1, 22, current_time, vib_sp2["x_axis"], upper_limit_vib_x2, lower_limit_vib_x2, outlier_status_vib_x2, filtered_x_vib_sp2),
            (1, 23, current_time, vib_sp2["y_axis"], upper_limit_vib_y2, lower_limit_vib_y2, outlier_status_vib_y2, filtered_y_vib_sp2),
            (1, 24, current_time, vib_sp2["z_axis"], upper_limit_vib_z2, lower_limit_vib_z2, outlier_status_vib_z2, filtered_z_vib_sp2)
        ]

        # print('*** sensor_data_list:', sensor_data_list)
        
        # 데이터베이스에 삽입
        # bulk_insert_to_db(sensor_data_list)
        batch_save_to_redis(sensor_data_list)
        
        # 함수 실행 시간 계산
        end = time.time()
        # print(f'실행 시간={end-start}')
    
        # 주기 설정
        sleep(0.01)
    
    # 데이터베이스 연결 종료
    conn.close()

###################################################

## 버전 확인 (hugging face 모델: keras<3.x)
import tensorflow as tf
import keras
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.models import load_model  # 모델 불러오기
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
print(tf.__version__)
print(keras.__version__)

data = pd.read_csv('./simulation_data.csv')
data = data.copy()
data = data[data['sensor_id']==7]
data

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import numpy as np
from sklearn.model_selection import train_test_split
import tensorflow as tf

# 시간 열을 datetime으로 변환
data['time'] = pd.to_datetime(data['time'])

# 'time'을 인덱스로 설정
data = data.set_index('time')

# 필요한 칼럼만 선택
data = data[['filtered_value', 'outlier_status']]

# 데이터 정규화
scaler = MinMaxScaler()
data[['value']] = scaler.fit_transform(data[['filtered_value']])

# 시계열 데이터로 변환
def create_sequences(df, sequence_length):
    xs, ys = [], []
    for i in range(len(df) - sequence_length):
        x = df.iloc[i:i+sequence_length][['value']].values
        y = df.iloc[i+sequence_length]['outlier_status']
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

sequence_length = 288  # 모델이 기대하는 시퀀스 길이
X, y = create_sequences(data, sequence_length)

# 데이터 차원 확인
print("X shape before reshape:", X.shape)

# 차원 조정 (마지막 차원을 1로 변경)
X = X[:, :, 0:1]

print("X shape after reshape:", X.shape)

# 훈련 세트와 테스트 세트로 나누기
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# 모델 로드
model = tf.keras.models.load_model("C:\\Users\\Jsystem\\.cache\\huggingface\\hub\\models--keras-io--timeseries-anomaly-detection\\snapshots\\57126012e02dcab3a653501f12cb599c4a51db7a")
model.summary()

# 모델 컴파일
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


# 모델 학습
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)

# 예측
y_pred = model.predict(X_test)

# 모델 평가
loss, accuracy = model.evaluate(X_test, y_test)
print(" ")
print("==========================")
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")




######################################################################################

## 버전 확인 (hugging face 모델: keras<3.x)
import tensorflow as tf
import keras
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.models import load_model  # 모델 불러오기
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
print(tf.__version__)
print(keras.__version__)

data = pd.read_csv('./preprocessed_data0912(symbolic).csv')

# '오후', '오전'을 AM/PM으로 변환하는 함수
def convert_korean_time_to_ampm(time_str):
    if '오전' in time_str:
        return time_str.replace('오전', 'AM')
    elif '오후' in time_str:
        return time_str.replace('오후', 'PM')
    else:
        return time_str

# 'time' 컬럼에 있는 '오전', '오후'를 AM/PM으로 변환
data['time'] = data['time'].apply(convert_korean_time_to_ampm)

# 날짜 및 시간 합치기
data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'], format='%Y-%m-%d %I:%M:%S %p')

# 불필요한 칼럼 제거
data = data.drop(columns=['test_id', 'date', 'time'])

# 칼럼순서 변경
data = data[['datetime', 'temp', 'rh', 'label']]

data['datetime'] = pd.to_datetime(data['datetime'])
data = data.set_index('datetime')

# 데이터 정규화
scaler = MinMaxScaler()
data[['temp', 'rh']] = scaler.fit_transform(data[['temp', 'rh']])

# 시계열 데이터로 변환
def create_sequences(df, sequence_length):
    xs, ys = [], []
    for i in range(len(df) - sequence_length):
        x = df.iloc[i:i+sequence_length][['temp', 'rh']].values
        y = df.iloc[i+sequence_length]['label']
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

sequence_length = 288  # 모델이 기대하는 시퀀스 길이
X, y = create_sequences(data, sequence_length)

# 현재 X shape 확인
print("X shape before reshape:", X.shape)

# 데이터 차원 조정 (마지막 차원을 1로 변경)
X = X[:, :, 0:1]

# 현재 X shape 확인
print("X shape after reshape:", X.shape)

# 훈련 세트와 테스트 세트로 나누기
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

import tensorflow as tf

model = tf.keras.models.load_model("C:\\Users\\Jsystem\\.cache\\huggingface\\hub\\models--keras-io--timeseries-anomaly-detection\\snapshots\\57126012e02dcab3a653501f12cb599c4a51db7a")
model.summary()

# 모델 컴파일
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 모델 학습
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)

# 예측
y_pred = model.predict(X_test)

# 모델 평가
loss, accuracy = model.evaluate(X_test, y_test)
print(" ")
print(" ")
print("==========================")
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")
